} else if (model_type == "logistic_elastic_net") {
# Elastic Net Logistic Regression using glmnet
library(glmnet)
model <- glmnet(as.matrix(predictors), target, family = "binomial", ...)
predictions <- predict(model, newx = as.matrix(test_predictors), type = "response", s = 0.1)
predictions <- ifelse(predictions > 0.5, 1, 0)
} else {
stop("Model type not recognized!")
}
# Return the model and predictions
return(list(model = model, predictions = predictions))
}
results_xgb <- run_model("xgboost", train_data, test_data, target_col = "outcome", nrounds = 100)
run_model <- function(model_type, train_data, test_data, target_col, ...) {
# Extract target variable from data
target <- train_data[[target_col]]
# Preprocess data (convert factors to numeric)
predictors <- train_data[, setdiff(names(train_data), target_col)]
test_predictors <- test_data[, setdiff(names(test_data), target_col)]
# Convert factors to numeric if necessary (e.g., one-hot encoding or label encoding)
predictors[] <- lapply(predictors, function(x) {
if (is.factor(x)) as.numeric(factor(x)) else x
})
test_predictors[] <- lapply(test_predictors, function(x) {
if (is.factor(x)) as.numeric(factor(x)) else x
})
# Initialize model and predictions variable
model <- NULL
predictions <- NULL
# Switch between model types
if (model_type == "logistic_regression") {
# Logistic regression using glm()
model <- glm(target ~ ., data = train_data, family = binomial, ...)
predictions <- predict(model, newdata = test_data, type = "response")
predictions <- ifelse(predictions > 0.5, 1, 0)
} else if (model_type == "decision_tree") {
# Decision Tree using rpart
library(rpart)
model <- rpart(target ~ ., data = train_data, method = "class", ...)
predictions <- predict(model, newdata = test_data, type = "class")
} else if (model_type == "random_forest") {
# Random Forest using randomForest
library(randomForest)
model <- randomForest(target ~ ., data = train_data, ...)
predictions <- predict(model, newdata = test_data)
} else if (model_type == "svm") {
# Support Vector Machine using e1071
library(e1071)
model <- svm(target ~ ., data = train_data, ...)
predictions <- predict(model, newdata = test_data)
} else if (model_type == "knn") {
# K-Nearest Neighbors using class
library(class)
model <- knn(train = predictors, test = test_predictors, cl = target, ...)
predictions <- model
} else if (model_type == "naive_bayes") {
# Naive Bayes using e1071
library(e1071)
model <- naiveBayes(target ~ ., data = train_data, ...)
predictions <- predict(model, newdata = test_data)
} #else if (model_type == "xgboost") {
# XGBoost
#library(xgboost)
# Convert predictors to numeric matrix for xgboost
#model_matrix <- xgb.DMatrix(data = as.matrix(predictors), label = target)
#test_matrix <- xgb.DMatrix(data = as.matrix(test_predictors))
# Use the correct argument name 'nround' (singular)
# model <- xgboost(data = model_matrix, nround = 100, objective = "binary:logistic", ...)
#predictions <- predict(model, test_matrix)
# predictions <- ifelse(predictions > 0.5, 1, 0)
} else if (model_type == "gbm") {
run_model <- function(model_type, train_data, test_data, target_col, ...) {
# Extract target variable from data
target <- train_data[[target_col]]
# Preprocess data (convert factors to numeric)
predictors <- train_data[, setdiff(names(train_data), target_col)]
test_predictors <- test_data[, setdiff(names(test_data), target_col)]
# Convert factors to numeric if necessary (e.g., one-hot encoding or label encoding)
predictors[] <- lapply(predictors, function(x) {
if (is.factor(x)) as.numeric(factor(x)) else x
})
test_predictors[] <- lapply(test_predictors, function(x) {
if (is.factor(x)) as.numeric(factor(x)) else x
})
# Initialize model and predictions variable
model <- NULL
predictions <- NULL
# Switch between model types
if (model_type == "logistic_regression") {
# Logistic regression using glm()
model <- glm(target ~ ., data = train_data, family = binomial, ...)
predictions <- predict(model, newdata = test_data, type = "response")
predictions <- ifelse(predictions > 0.5, 1, 0)
} else if (model_type == "decision_tree") {
# Decision Tree using rpart
library(rpart)
model <- rpart(target ~ ., data = train_data, method = "class", ...)
predictions <- predict(model, newdata = test_data, type = "class")
} else if (model_type == "random_forest") {
# Random Forest using randomForest
library(randomForest)
model <- randomForest(target ~ ., data = train_data, ...)
predictions <- predict(model, newdata = test_data)
} else if (model_type == "svm") {
# Support Vector Machine using e1071
library(e1071)
model <- svm(target ~ ., data = train_data, ...)
predictions <- predict(model, newdata = test_data)
} else if (model_type == "knn") {
# K-Nearest Neighbors using class
library(class)
model <- knn(train = predictors, test = test_predictors, cl = target, ...)
predictions <- model
} else if (model_type == "naive_bayes") {
# Naive Bayes using e1071
library(e1071)
model <- naiveBayes(target ~ ., data = train_data, ...)
predictions <- predict(model, newdata = test_data)
} #else if (model_type == "xgboost") {
# XGBoost
#library(xgboost)
# Convert predictors to numeric matrix for xgboost
#model_matrix <- xgb.DMatrix(data = as.matrix(predictors), label = target)
#test_matrix <- xgb.DMatrix(data = as.matrix(test_predictors))
# Use the correct argument name 'nround' (singular)
# model <- xgboost(data = model_matrix, nround = 100, objective = "binary:logistic", ...)
#predictions <- predict(model, test_matrix)
# predictions <- ifelse(predictions > 0.5, 1, 0)
else if (model_type == "gbm") {
# Gradient Boosting Machine using gbm
library(gbm)
model <- gbm(target ~ ., data = train_data, distribution = "bernoulli", ...)
predictions <- predict(model, newdata = test_data, type = "response")
predictions <- ifelse(predictions > 0.5, 1, 0)
} else if (model_type == "neural_network") {
# Neural Network using nnet
library(nnet)
model <- nnet(target ~ ., data = train_data, size = 5, linout = FALSE, ...)
predictions <- predict(model, newdata = test_data, type = "class")
} else if (model_type == "logistic_elastic_net") {
# Elastic Net Logistic Regression using glmnet
library(glmnet)
model <- glmnet(as.matrix(predictors), target, family = "binomial", ...)
predictions <- predict(model, newx = as.matrix(test_predictors), type = "response", s = 0.1)
predictions <- ifelse(predictions > 0.5, 1, 0)
} else {
stop("Model type not recognized!")
}
# Return the model and predictions
return(list(model = model, predictions = predictions))
}
results_xgb <- run_model("xgboost", train_data, test_data, target_col = "outcome", nrounds = 100)
results_xgb <- run_model("logistic regression", train_data, test_data, target_col = "outcome", nrounds = 100)
results_xgb <- run_model("svm", train_data, test_data, target_col = "outcome", nrounds = 100)
model_xgb <- results_xgb$model
predictions_xgb <- results_xgb$predictions
conf_matrix <- confusionMatrix(predictions_svm, test_data$outcome)
conf_matrix <- confusionMatrix(predictions_svm, test_data$outcome)
predictions_svm <- results_svm$predictions
results_svm <- run_model("svm", train_data, test_data, target_col = "outcome", nrounds = 100)
model_svm <- results_xgb$model
predictions_svm <- results_svm$predictions
conf_matrix <- confusionMatrix(predictions_svm, test_data$outcome)
library(caret)
conf_matrix <- confusionMatrix(predictions_svm, test_data$outcome)
print(conf_matrix)
print(conf_matrix$byClass)
#run logistic regression
logistic_model <- glm(target ~ ., data = train_data, family = binomial)
library(tidyverse)
install.packages("caret")
library(caret)
install.packages("dslabs")
horse_colic_data <- read.csv("C:/Users/NANA/Downloads/horse.csv")
# View the first few rows
head(horse_colic_data)
glimpse(horse_colic_data)
install.packages("tidyverse")
library(tidyverse)
glimpse(horse_colic_data)
str(horse_colic_data)
colnames(horse_colic_data)
nrow(horse_colic_data)
ncol(horse_colic_data)
dim(horse_colic_data)
# column types whether categorical or numeric
sapply(horse_colic_data,class)
#check for missing values
anyNA(horse_colic_data)
#is.na(horse_colic_data)
sum(is.na(horse_colic_data))
#summary statistics for checking na
summary(horse_colic_data)
#checking columns with na
colSums(is.na(horse_colic_data))
#checking for distinct values in certain categorical columns
unique(horse_colic_data$temp_of_extremities)
length(unique(horse_colic_data$temp_of_extremities)) # number of distinct values
table(horse_colic_data$mucous_membrane)
horse_colic_data %>% distinct(abdomo_appearance)
n_distinct(horse_colic_data$abdomo_appearance) # number of distinct value
#numerical variables
num_variables <- c("rectal_temp","pulse","respiratory_rate","nasogastric_reflux_ph","packed_cell_volume","total_protein","abdomo_protein")
imputer <- function(data,columns){
for (col in columns){
avg_x <- mean(data[[col]],na.rm=TRUE)
data[[col]][is.na(data[[col]])] <- avg_x
}
return(data)
}
horse_colic_data <- imputer(horse_colic_data,num_variables)
#check for missing values after imputing numerical variables
colSums(is.na(horse_colic_data))
#removing hospital_number column
horse_colic_data <- horse_colic_data %>%select(-hospital_number)
colnames(horse_colic_data)
#checking  all categorical variables
cat_variables <- horse_colic_data %>% select(-all_of(num_variables))
cat_variables
# Function to calculate mode (most frequent value)
get_mode <- function(x) {
freq_table <- table(x)  # Create a frequency table of the values
mode_val <- names(freq_table)[which.max(freq_table)]  # Find the value with the highest frequency
return(mode_val)
}
#convert all characters to factors
for (col in names(cat_variables)) {
if (is.character(horse_colic_data[[col]])) {
horse_colic_data[[col]] <- as.factor(horse_colic_data[[col]])
}
}
# Loop through each categorical variable column in the dataframe
for (col in names(cat_variables)) {
# Check if the column is a factor (categorical data)
if (is.factor(horse_colic_data[[col]])) {
# Check for NAs before replacing them
if (sum(is.na(horse_colic_data[[col]])) > 0) {
# Get the mode (most frequent value) for each column
mode_val <- get_mode(horse_colic_data[[col]])  # Extract the column using [[col]]
# Impute NAs in the column with the mode
horse_colic_data[[col]][is.na(horse_colic_data[[col]])] <- mode_val
}
} else {
# If the column is not a factor, print a message (optional)
print(paste(col, "is not a factor. It will not be processed."))
}
}
#checking for the unique set in all categorical
unique_value_list <- list()
for (col in names(cat_variables)){
uniqueness <- length(unique(cat_variables[[col]]))
unique_value_list[[col]] <- uniqueness
}
unique_value_list
# Split the code into separate components for each lesion
split_code <- function(code) {
# Extract each part of code
site <- as.factor(substr(code, 1, 1))  # First digit
type <- as.factor(substr(code, 2, 2))  # Second digit
subtype <- as.factor(substr(code, 3, 3))  # Third digit
specific_code <- as.factor(substr(code, 4, 4))  # Fourth digit
# Return the split parts as a list or dataframe
return(c(site, type, subtype, specific_code))
}
# Apply the function to lesion_1, lesion_2, and lesion_3
horse_colic_data$site_1 <- sapply(horse_colic_data$lesion_1, function(x) split_code(x)[1])
horse_colic_data$type_1 <- sapply(horse_colic_data$lesion_1, function(x) split_code(x)[2])
horse_colic_data$subtype_1 <- sapply(horse_colic_data$lesion_1, function(x) split_code(x)[3])
horse_colic_data$specific_code_1 <- sapply(horse_colic_data$lesion_1, function(x) split_code(x)[4])
horse_colic_data$site_2 <- sapply(horse_colic_data$lesion_2, function(x) split_code(x)[1])
horse_colic_data$type_2 <- sapply(horse_colic_data$lesion_2, function(x) split_code(x)[2])
horse_colic_data$subtype_2 <- sapply(horse_colic_data$lesion_2, function(x) split_code(x)[3])
horse_colic_data$specific_code_2 <- sapply(horse_colic_data$lesion_2, function(x) split_code(x)[4])
horse_colic_data$site_3 <- sapply(horse_colic_data$lesion_3, function(x) split_code(x)[1])
horse_colic_data$type_3 <- sapply(horse_colic_data$lesion_3, function(x) split_code(x)[2])
horse_colic_data$subtype_3 <- sapply(horse_colic_data$lesion_3, function(x) split_code(x)[3])
horse_colic_data$specific_code_3 <- sapply(horse_colic_data$lesion_3, function(x) split_code(x)[4])
#verify dataset is in right format for prediction
head(horse_colic_data)
str(horse_colic_data)
sapply(horse_colic_data,class)
#removing columns not needed for machine learning
horse_colic_data <- horse_colic_data %>% select(-lesion_1,-lesion_2,-lesion_3)
horse_colic_data
#getting train and test data
trainIndex <- createDataPartition(horse_colic_data$outcome,p=0.8,list = FALSE)
train_data <- horse_colic_data[trainIndex,]
test_data <- horse_colic_data[-trainIndex,]
#installing packages
install.packages("rpart")         # Decision Tree
install.packages("randomForest")  # Random Forest
install.packages("e1071")         # SVM, Naive Bayes
install.packages("class")         # KNN
install.packages("gbm")           # Gradient Boosting Machine
install.packages("nnet")          # Neural Network
install.packages("glmnet")        # Elastic Net Logistic Regression
#run rf model
library(randomForest)
rf_model <- randomForest(outcome ~ ., data = train_data, importance = TRUE, ntree = 100)
summary(rf_model)
rf_predictions <- predict(rf_model,newdata = test_data)
conf_matrix <- confusionMatrix(rf_predictions, test_data$outcome)
print(conf_matrix)
print(conf_matrix$byClass)
importance(rf_model)
#run logistic regression
logistic_model <- glm(target ~ ., data = train_data, family = binomial)
#run logistic regression
logistic_model <- glm(outcome ~ ., data = train_data, family = binomial)
predictions <- predict(model, newdata = test_data, type = "response")
predictions <- predict(logistic_model, newdata = test_data, type = "response")
#run logistic regression
logistic_model <- glm(outcome ~ ., data = train_data, family = binomial)
predictions <- predict(logistic_model, newdata = test_data, type = "response")
predictions <- predict(logistic_model, newdata = test_data)
#run logistic regression
logistic_model <- glm(outcome ~ ., data = train_data, family = binomial)
multinom_model <- multinom(outcome ~ ., data = train_data)
install.packages("nnet")
library(nnet)
multinom_model <- multinom(outcome ~ ., data = train_data)
summary(multinom_model)
predicted_probs <- predict(multinom_model, newdata = test_data, type = "probs")
# Get the predicted class labels (based on highest probability)
predicted_classes <- predict(multinom_model, newdata = test_data)
# Confusion matrix to assess model performance
conf_matrix <- confusionMatrix(predicted_classes, test_data$outcome)
install.packages("caret")
library(caret)
# Confusion matrix to assess model performance
conf_matrix <- confusionMatrix(predicted_classes, test_data$outcome)
print(conf_matrix)
# Optionally, you can compute accuracy or other metrics directly from the confusion matrix
accuracy <- conf_matrix$overall["Accuracy"]
print(paste("Accuracy: ", accuracy))
#
library(rpart)
decision_model <- rpart(target ~ ., data = train_data, method = "class")
decision_model <- rpart(outcome ~ ., data = train_data, method = "class")
predictions <- predict(decision_model, newdata = test_data, type = "class")
#run multinomial logistic regression
library(nnet)
rpart.plot(dt_model, main = "Decision Tree for Horse Colic Outcome", extra = 104)
library(rpart.plot)
install.packages(rpart.plot)
library(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
decision_model <- rpart(outcome ~ ., data = train_data, method = "class")
summary(decision_model)
rpart.plot(dt_model, main = "Decision Tree for Horse Colic Outcome", extra = 104)
rpart.plot(decision_model, main = "Decision Tree for Horse Colic Outcome", extra = 104)
#visualize decision tree
rpart.plot(decision_model, main = "Decision Tree for Horse Colic Outcome", extra = 104)
predicted_classes <- predict(decision_model, newdata = test_data, type = "class")
conf_matrix <- confusionMatrix(predicted_classes, test_data$outcome)
print(conf_matrix)
accuracy <- conf_matrix$overall["Accuracy"]
print(paste("Accuracy: ", accuracy))
#run svm
svm_model <- svm(outcome ~ ., data = train_data, kernel = "radial", cost = 1, gamma = 0.1)
#run svm
library(e1071)
svm_model <- svm(outcome ~ ., data = train_data, kernel = "radial", cost = 1, gamma = 0.1)
summary(svm_model)
predicted_classes <- predict(svm_model, newdata = test_data)
conf_matrix <- confusionMatrix(predicted_classes, test_data$outcome)
print(conf_matrix)
accuracy <- conf_matrix$overall["Accuracy"]
print(paste("Accuracy: ", accuracy))
naive_bayes_model <- naiveBayes(outcome ~ ., data = train_data)
# Check model summary
summary(naive_bayes_model)
# 5. Make predictions on the test data
predicted_classes <- predict(naive_bayes_model, newdata = test_data)
# 6. Evaluate the model using a confusion matrix
conf_matrix <- confusionMatrix(predicted_classes, test_data$outcome)
print(conf_matrix)
# Optionally, you can compute accuracy or other metrics directly from the confusion matrix
accuracy <- conf_matrix$overall["Accuracy"]
print(paste("Accuracy: ", accuracy))
#run knn
train_data_scaled <- train_data
test_data_scaled <- test_data
# Scale the predictors (excluding the outcome variable)
train_data_scaled[, -which(names(train_data) == "outcome")] <- scale(train_data[, -which(names(train_data) == "outcome")])
#run knn
library(class)
model <- knn(train = predictors, test = test_predictors, cl = target, ...)
model <- knn(train = predictors, test = test_predictors, cl = outcome)
#run gbm
gbm_model <- gbm(outcome ~ .,
data = train_data,
distribution = "multinomial",  # For multi-class classification
n.trees = 1000,                # Number of boosting iterations (trees)
interaction.depth = 3,         # Max depth of trees
shrinkage = 0.01,              # Learning rate
cv.folds = 5,                  # Cross-validation folds
n.cores = NULL,                # Number of cores to use (NULL uses all available)
verbose = TRUE)
#run gbm
library(gbm)
gbm_model <- gbm(outcome ~ .,
data = train_data,
distribution = "multinomial",  # For multi-class classification
n.trees = 1000,                # Number of boosting iterations (trees)
interaction.depth = 3,         # Max depth of trees
shrinkage = 0.01,              # Learning rate
cv.folds = 5,                  # Cross-validation folds
n.cores = NULL,                # Number of cores to use (NULL uses all available)
verbose = TRUE)
#Plot the variable importance
# This will show the importance of each feature
plot(gbm_model, i.var = 1)  # Plot importance of the first variable
summary(gbm_model)          # Summarize the model
predictions_gbm <- predict(gbm_model, test_data, n.trees = 1000, type = "response")
# Convert the predictions to class labels
# Since the predictions are in the form of probabilities, we take the class with the highest probability
predicted_class <- apply(predictions_gbm, 1, function(x) colnames(predictions_gbm)[which.max(x)])
conf_matrix <- confusionMatrix(factor(predicted_class), test_data$outcome)
print(conf_matrix)
accuracy <- conf_matrix$overall["Accuracy"]
print(paste("Accuracy: ", accuracy))
# Example of tuning the GBM model using caret's train() function
train_control <- trainControl(method = "cv", number = 5)
# Tuning GBM using caret's train() function
tuned_model <- train(outcome ~ ., data = train_data, method = "gbm", trControl = train_control,
tuneGrid = expand.grid(n.trees = c(500, 1000),
interaction.depth = c(1, 3, 5),
shrinkage = c(0.01, 0.1),
n.minobsinnode = 10))
warnings()
# Best model after tuning
print(tuned_model)
# Neural networks are sensitive to the scale of input features, so we will scale the predictors
train_data_scaled <- train_data
test_data_scaled <- test_data
# Scale the predictors (excluding the outcome variable)
train_data_scaled[, -which(names(train_data) == "outcome")] <- scale(train_data[, -which(names(train_data) == "outcome")])
# Neural networks are sensitive to the scale of input features, so we will scale the predictors
numeric_columns <- sapply(train_data, is.numeric)
train_data_scaled <- train_data
test_data_scaled <- test_data
# Scale the predictors (excluding the outcome variable)
train_data_scaled[, -which(names(train_data) == "outcome")] <- scale(train_data[, -which(names(train_data) == "outcome")])
# Neural networks are sensitive to the scale of input features, so we will scale the predictors
numeric_columns <- sapply(train_data, is.numeric)
train_data_scaled <- train_data
test_data_scaled <- test_data
# Scale the predictors (excluding the outcome variable)
train_data_scaled[, numeric_columns] <- scale(train_data[, numeric_columns])
test_data_scaled[, numeric_columns] <- scale(test_data[, numeric_columns])
# Train the neural network using nnet function
# The formula is outcome ~ . (target variable 'outcome' and all other variables as predictors)
nn_model <- nnet(outcome ~ .,
data = train_data_scaled,
size = 10,          # Number of hidden units (neurons)
linout = FALSE,     # Classification task (not regression)
decay = 0.001,      # L2 regularization (helps avoid overfitting)
maxit = 1000,       # Maximum number of iterations (epochs)
trace = TRUE)       # Print progress
# Neural networks are sensitive to the scale of input features, so we will scale the predictors
numeric_columns <- sapply(train_data, is.numeric)
train_data_scaled <- train_data
test_data_scaled <- test_data
# Scale the predictors (excluding the outcome variable)
train_data_scaled[, numeric_columns] <- scale(train_data[, numeric_columns])
test_data_scaled[, numeric_columns] <- scale(test_data[, numeric_columns])
# Train the neural network using nnet function
# The formula is outcome ~ . (target variable 'outcome' and all other variables as predictors)
nn_model <- nnet(outcome ~ .,
data = train_data_scaled,
size = 3,          # Number of hidden units (neurons)
linout = FALSE,     # Classification task (not regression)
decay = 0.001,      # L2 regularization (helps avoid overfitting)
maxit = 1000,       # Maximum number of iterations (epochs)
trace = TRUE)       # Print progress
predictions_nn <- predict(nn_model, test_data_scaled, type = "class")
conf_matrix <- confusionMatrix(predictions_nn, test_data$outcome)
# Optionally, you can compute accuracy or other metrics directly from the confusion matrix
accuracy <- conf_matrix$overall["Accuracy"]
print(paste("Accuracy: ", accuracy))
# Cross-validation using caret
train_control <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation
tuned_nn_model <- train(outcome ~ ., data = train_data, method = "nnet",
trControl = train_control,
tuneGrid = expand.grid(size = c(3, 5, 7), decay = c(0.001, 0.01)),
linout = FALSE, trace = FALSE)
# Display the best model found by cross-validation
print(tuned_nn_model)
# Convert predictors to matrix and outcome to vector
x_train <- as.matrix(train_data_scaled[, -which(names(train_data) == "outcome")])  # Exclude the 'outcome' column
y_train <- train_data_scaled$outcome  # Target variable
# 5. Fit a glmnet model (Elastic Net)
# Note: alpha = 0.5 for Elastic Net (mix of Lasso and Ridge)
glmnet_model <- glmnet(x_train, y_train, family = "multinomial", alpha = 0.5)
library(glmnet)
# Convert predictors to matrix and outcome to vector
x_train <- as.matrix(train_data_scaled[, -which(names(train_data) == "outcome")])  # Exclude the 'outcome' column
y_train <- train_data_scaled$outcome  # Target variable
# 5. Fit a glmnet model (Elastic Net)
# Note: alpha = 0.5 for Elastic Net (mix of Lasso and Ridge)
glmnet_model <- glmnet(x_train, y_train, family = "multinomial", alpha = 0.5)
# 6. Make Predictions
# Prepare the test data
x_test <- as.matrix(test_data_scaled[, -which(names(test_data) == "outcome")])
# Predict using the fitted glmnet model
predictions_glmnet <- predict(glmnet_model, newx = x_test, type = "class")
# Convert predictions to factor for comparison with actual outcomes
predictions_glmnet <- factor(predictions_glmnet, levels = levels(y_train))
# 7. Evaluate the model using confusion matrix
conf_matrix <- confusionMatrix(predictions_glmnet, test_data$outcome)
